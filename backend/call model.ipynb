{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12509,
     "status": "ok",
     "timestamp": 1750599937157,
     "user": {
      "displayName": "Pranaya Jandial",
      "userId": "08091217684900804801"
     },
     "user_tz": -330
    },
    "id": "3M3357GX0Bob",
    "outputId": "7544e419-1469-456b-edd1-671cf8612efe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: datasets in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: gradio in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (5.34.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: openai-whisper in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (20240930)\n",
      "Requirement already satisfied: torch in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (0.115.13)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (0.6.0)\n",
      "Requirement already satisfied: gradio-client==1.10.3 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (1.10.3)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (3.10.18)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (11.2.1)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (2.11.7)\n",
      "Requirement already satisfied: pydub in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (4.14.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio) (0.34.3)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from gradio-client==1.10.3->gradio) (15.0.1)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: numba in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from openai-whisper) (0.61.2)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from openai-whisper) (10.7.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from openai-whisper) (0.9.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: certifi in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from httpx>=0.24.1->gradio) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from numba->openai-whisper) (0.44.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets gradio scikit-learn pandas openai-whisper torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 23417,
     "status": "ok",
     "timestamp": 1750599960576,
     "user": {
      "displayName": "Pranaya Jandial",
      "userId": "08091217684900804801"
     },
     "user_tz": -330
    },
    "id": "UZo0Tzh71P_f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samad\\OneDrive\\Documents\\cdac hackathon\\my-project\\backend\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import whisper\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    BertTokenizerFast,\n",
    "    BertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    TextClassificationPipeline\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import gradio as gr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1750599960579,
     "user": {
      "displayName": "Pranaya Jandial",
      "userId": "08091217684900804801"
     },
     "user_tz": -330
    },
    "id": "_Wzmid7q1P6k"
   },
   "outputs": [],
   "source": [
    "# STEP 1: Load and preprocess data\n",
    "df = pd.read_csv('./fraud_calls_data.csv', header=None)\n",
    "df.columns = ['label', 'call_text']\n",
    "df = df.dropna(subset=['call_text', 'label'])\n",
    "df['label'] = df['label'].map({'normal': 0, 'fraud': 1})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "36e7e451874f4c0e9c30494e34f43e91",
      "414003e088834d0a8262a655f69834ba",
      "1d68453c0f784e81be079014b29a2388",
      "85311277a2c74ed7a0d4c41aa97bfbf4",
      "e446da81392a4d2f9418d276c5e630b3",
      "92bf696c95e447cc89a052e3b576cb7c",
      "ee4e82af6f604d1fb05e003891b1a0d9",
      "99317d8e00f34a5ba6c6c151c0b5b788",
      "268fe6b11d8e4eb8aeb34ed89458abb1",
      "f48b4aeda99649bfa725aa52b33f1deb",
      "a2bd55945fe84b8085090022c087fc2d"
     ]
    },
    "executionInfo": {
     "elapsed": 2294,
     "status": "ok",
     "timestamp": 1750599962874,
     "user": {
      "displayName": "Pranaya Jandial",
      "userId": "08091217684900804801"
     },
     "user_tz": -330
    },
    "id": "qQL98VG21P2m",
    "outputId": "b3490626-1765-4c13-b76e-416a14864aa4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5925/5925 [00:00<00:00, 7818.62 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Tokenization and Hugging Face dataset\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "dataset = Dataset.from_pandas(df[['call_text', 'label']])\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch['call_text'], truncation=True, padding=True, max_length=128)\n",
    "\n",
    "dataset = dataset.map(tokenize_function, batched=True)\n",
    "dataset = dataset.rename_column(\"label\", \"labels\")\n",
    "dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1750599962910,
     "user": {
      "displayName": "Pranaya Jandial",
      "userId": "08091217684900804801"
     },
     "user_tz": -330
    },
    "id": "qMFt82iV1PzN"
   },
   "outputs": [],
   "source": [
    "\n",
    "# STEP 3: Split dataset\n",
    "data_split = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = data_split[\"train\"]\n",
    "eval_dataset = data_split[\"test\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10950,
     "status": "ok",
     "timestamp": 1750599973862,
     "user": {
      "displayName": "Pranaya Jandial",
      "userId": "08091217684900804801"
     },
     "user_tz": -330
    },
    "id": "Dk7vK6Wx3CDt",
    "outputId": "6dd3e67b-cae0-4f81-cc87-0e4e994f1781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samad\\onedrive\\documents\\cdac hackathon\\my-project\\backend\\venv\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "executionInfo": {
     "elapsed": 540652,
     "status": "ok",
     "timestamp": 1750600684025,
     "user": {
      "displayName": "Pranaya Jandial",
      "userId": "08091217684900804801"
     },
     "user_tz": -330
    },
    "id": "Heox7FD75GnH",
    "outputId": "b0590353-38ae-4f8e-9231-6351b7d03b39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1188' max='1188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1188/1188 3:33:17, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.054011</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.035979</td>\n",
       "      <td>0.990717</td>\n",
       "      <td>0.953586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.044573</td>\n",
       "      <td>0.991561</td>\n",
       "      <td>0.957265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.049031</td>\n",
       "      <td>0.991561</td>\n",
       "      <td>0.957265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1188, training_loss=0.04054746734172808, metrics={'train_runtime': 12828.4493, 'train_samples_per_second': 1.478, 'train_steps_per_second': 0.093, 'total_flos': 1247146402406400.0, 'train_loss': 0.04054746734172808, 'epoch': 4.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 4: Load and train BERT\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.tensor(logits).argmax(dim=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, predictions),\n",
    "        \"f1\": f1_score(labels, predictions)\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert-fraud-checkpoint\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=[]  # Disable wandb\n",
    ")\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1750600684272,
     "user": {
      "displayName": "Pranaya Jandial",
      "userId": "08091217684900804801"
     },
     "user_tz": -330
    },
    "id": "-ry0DdTT4RW7",
    "outputId": "1f76009b-1d98-45ec-c5cf-65ab6c85571a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model from ./bert-fraud-checkpoint\\checkpoint-891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifying example texts:\n",
      "Text: 'Hello, this is a call from your bank regarding a suspicious transaction.' -> Predicted: fraud (Score: 0.9982)\n",
      "Text: 'Hi, just calling to catch up.' -> Predicted: normal (Score: 0.9998)\n",
      "Text: 'You have won a prize! Please provide your bank details to claim it.' -> Predicted: fraud (Score: 0.9980)\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Create a text classification pipeline\n",
    "# Load the best model from the checkpoints\n",
    "model_path = trainer.state.best_model_checkpoint\n",
    "if model_path is None:\n",
    "    # If no best model checkpoint is found (e.g., early stopping not used or only one epoch),\n",
    "    # use the last checkpoint or the initial model if only one epoch was run.\n",
    "    # For simplicity, let's assume the model object 'model' is already the trained one\n",
    "    # after trainer.train() completes. If you need to load a specific epoch's model,\n",
    "    # you would typically load from the output_dir.\n",
    "    print(\"No best model checkpoint found, using the model trained in the last epoch.\")\n",
    "    model_to_use = model\n",
    "else:\n",
    "    print(f\"Loading best model from {model_path}\")\n",
    "    model_to_use = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "pipeline = TextClassificationPipeline(\n",
    "    model=model_to_use,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1 # Use GPU if available\n",
    ")\n",
    "\n",
    "# Example usage:\n",
    "example_texts = [\n",
    "    \"Hello, this is a call from your bank regarding a suspicious transaction.\",\n",
    "    \"Hi, just calling to catch up.\",\n",
    "    \"You have won a prize! Please provide your bank details to claim it.\"\n",
    "]\n",
    "\n",
    "print(\"\\nClassifying example texts:\")\n",
    "for text in example_texts:\n",
    "    result = pipeline(text)\n",
    "    predicted_label = \"fraud\" if result[0]['label'] == 'LABEL_1' else \"normal\"\n",
    "    score = result[0]['score']\n",
    "    print(f\"Text: '{text}' -> Predicted: {predicted_label} (Score: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1750600684279,
     "user": {
      "displayName": "Pranaya Jandial",
      "userId": "08091217684900804801"
     },
     "user_tz": -330
    },
    "id": "uDqs58f45mr0",
    "outputId": "0958a88c-9cdf-4397-eff0-4816e807cace"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "c:\\Users\\samad\\OneDrive\\Documents\\cdac hackathon\\my-project\\backend\\venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Prediction pipeline\n",
    "pipe = TextClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_all_scores=True,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3147,
     "status": "ok",
     "timestamp": 1750600687428,
     "user": {
      "displayName": "Pranaya Jandial",
      "userId": "08091217684900804801"
     },
     "user_tz": -330
    },
    "id": "T9qSR_Pv6D6N",
    "outputId": "6565ba01-0afd-4861-b3c9-f4af2ea47e54"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:34<00:00, 4.15MiB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# STEP 6: Whisper model for transcription\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "# STEP 7: Risk scoring logic\n",
    "def calculate_risk_score(prob):\n",
    "    if prob >= 0.85:\n",
    "        return \"Critical\"\n",
    "    elif prob >= 0.65:\n",
    "        return \"High\"\n",
    "    elif prob >= 0.35:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1750600687447,
     "user": {
      "displayName": "Pranaya Jandial",
      "userId": "08091217684900804801"
     },
     "user_tz": -330
    },
    "id": "yKtmPoE06E5a"
   },
   "outputs": [],
   "source": [
    "# STEP 8: Fusion layer for prediction\n",
    "def predict_fraud(text, trust_score):\n",
    "    try:\n",
    "        result = pipe(text)[0]\n",
    "        model_prob = next((item['score'] for item in result if item['label'] == 'LABEL_1'), 0.0)\n",
    "        alpha = 0.7\n",
    "        fused_score = alpha * model_prob + (1 - alpha) * (1 - trust_score)\n",
    "        label = \"Fraud\" if fused_score >= 0.5 else \"Normal\"\n",
    "        risk = calculate_risk_score(fused_score)\n",
    "        return label, f\"{model_prob:.4f}\", f\"{fused_score:.4f}\", risk\n",
    "    except Exception as e:\n",
    "        return \"Error\", \"Error\", \"Error\", str(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1750600687449,
     "user": {
      "displayName": "Pranaya Jandial",
      "userId": "08091217684900804801"
     },
     "user_tz": -330
    },
    "id": "nmGuRql86HOq"
   },
   "outputs": [],
   "source": [
    "# STEP 9: Voice + Trust input wrapper\n",
    "def transcribe_and_predict(audio_file, trust_score):\n",
    "    try:\n",
    "        result = whisper_model.transcribe(audio_file)\n",
    "        transcript = result['text']\n",
    "        prediction = predict_fraud(transcript, trust_score)\n",
    "        return prediction + (transcript,)\n",
    "    except Exception as e:\n",
    "        return \"Error\", \"Error\", \"Error\", str(e), \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1750600687460,
     "user": {
      "displayName": "Pranaya Jandial",
      "userId": "08091217684900804801"
     },
     "user_tz": -330
    },
    "id": "DJft1lPh6Lvc"
   },
   "outputs": [],
   "source": [
    "# STEP 10: Gradio UI\n",
    "def build_interface():\n",
    "    text_input_tab = gr.Interface(\n",
    "        fn=predict_fraud,\n",
    "        inputs=[\n",
    "            gr.Textbox(label=\"Enter Call Transcript\"),\n",
    "            gr.Slider(minimum=0.0, maximum=1.0, value=0.5, step=0.01, label=\"User Trust Score\")\n",
    "        ],\n",
    "        outputs=[\n",
    "            gr.Label(label=\"Prediction\"),\n",
    "            gr.Label(label=\"Model Fraud Probability\"),\n",
    "            gr.Label(label=\"Fused Risk Score\"),\n",
    "            gr.Label(label=\"Risk Level\")\n",
    "        ],\n",
    "        title=\"Text-based Fraud Detection\",\n",
    "        description=\"Enter a call transcript and trust score to check fraud.\"\n",
    "    )\n",
    "\n",
    "    voice_input_tab = gr.Interface(\n",
    "        fn=transcribe_and_predict,\n",
    "        inputs=[\n",
    "            gr.Audio(type=\"filepath\", label=\"Upload Call Recording (wav/mp3)\"),\n",
    "            gr.Slider(minimum=0.0, maximum=1.0, value=0.5, step=0.01, label=\"User Trust Score\")\n",
    "        ],\n",
    "        outputs=[\n",
    "            gr.Label(label=\"Prediction\"),\n",
    "            gr.Label(label=\"Model Fraud Probability\"),\n",
    "            gr.Label(label=\"Fused Risk Score\"),\n",
    "            gr.Label(label=\"Risk Level\"),\n",
    "            gr.Textbox(label=\"Transcribed Text\")\n",
    "        ],\n",
    "        title=\"Voice-based Fraud Detection\",\n",
    "        description=\"Upload a call recording and get fraud detection with risk analysis.\"\n",
    "    )\n",
    "\n",
    "    demo = gr.TabbedInterface([text_input_tab, voice_input_tab], [\"Text Input\", \"Voice Input\"])\n",
    "    return demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "executionInfo": {
     "elapsed": 3204,
     "status": "ok",
     "timestamp": 1750600690671,
     "user": {
      "displayName": "Pranaya Jandial",
      "userId": "08091217684900804801"
     },
     "user_tz": -330
    },
    "id": "oDvJmWdJ6O-S",
    "outputId": "0d24fa7b-0178-40f4-ea5e-058fb1250f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "When localhost is not accessible, a shareable link must be created. Please set share=True or check your proxy settings to allow access to localhost.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Launch the Gradio app\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mbuild_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\samad\\OneDrive\\Documents\\cdac hackathon\\my-project\\backend\\venv\\Lib\\site-packages\\gradio\\blocks.py:2831\u001b[39m, in \u001b[36mBlocks.launch\u001b[39m\u001b[34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, share_server_tls_certificate, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, mcp_server, _frontend, i18n)\u001b[39m\n\u001b[32m   2823\u001b[39m \u001b[38;5;66;03m# If running in a colab or not able to access localhost,\u001b[39;00m\n\u001b[32m   2824\u001b[39m \u001b[38;5;66;03m# a shareable link must be created.\u001b[39;00m\n\u001b[32m   2825\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2826\u001b[39m     _frontend\n\u001b[32m   2827\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m wasm_utils.IS_WASM\n\u001b[32m   2828\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m networking.url_ok(\u001b[38;5;28mself\u001b[39m.local_url)\n\u001b[32m   2829\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.share\n\u001b[32m   2830\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m2831\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2832\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWhen localhost is not accessible, a shareable link must be created. Please set share=True or check your proxy settings to allow access to localhost.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2833\u001b[39m     )\n\u001b[32m   2835\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_colab \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[32m   2836\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m debug:\n",
      "\u001b[31mValueError\u001b[39m: When localhost is not accessible, a shareable link must be created. Please set share=True or check your proxy settings to allow access to localhost."
     ]
    }
   ],
   "source": [
    "\n",
    "# Launch the Gradio app\n",
    "build_interface().launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_to_use' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m final_model_path = \u001b[33m\"\u001b[39m\u001b[33m./backend/bert_call_model\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel_to_use\u001b[49m.save_pretrained(final_model_path)\n\u001b[32m      3\u001b[39m tokenizer.save_pretrained(final_model_path)\n",
      "\u001b[31mNameError\u001b[39m: name 'model_to_use' is not defined"
     ]
    }
   ],
   "source": [
    "final_model_path = \"./backend/bert_call_model\"\n",
    "model_to_use.save_pretrained(final_model_path)\n",
    "tokenizer.save_pretrained(final_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from best checkpoint: ./bert-fraud-checkpoint\\checkpoint-891\n",
      "✅ Model and tokenizer saved to: ./backend/bert_call_model\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Get best model from checkpoint, or fallback to trained model\n",
    "model_path = trainer.state.best_model_checkpoint\n",
    "\n",
    "if model_path is None:\n",
    "    print(\"No checkpoint found, using model from last epoch.\")\n",
    "    model_to_use = model\n",
    "else:\n",
    "    print(f\"Loading model from best checkpoint: {model_path}\")\n",
    "    model_to_use = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Define final save path\n",
    "final_model_path = \"./backend/bert_call_model\"\n",
    "\n",
    "# Save model and tokenizer\n",
    "model_to_use.save_pretrained(final_model_path)\n",
    "tokenizer.save_pretrained(final_model_path)\n",
    "\n",
    "print(\"✅ Model and tokenizer saved to:\", final_model_path)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMdqB7zUOmPtoIenwgC/oIB",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1d68453c0f784e81be079014b29a2388": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99317d8e00f34a5ba6c6c151c0b5b788",
      "max": 5925,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_268fe6b11d8e4eb8aeb34ed89458abb1",
      "value": 5925
     }
    },
    "268fe6b11d8e4eb8aeb34ed89458abb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "36e7e451874f4c0e9c30494e34f43e91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_414003e088834d0a8262a655f69834ba",
       "IPY_MODEL_1d68453c0f784e81be079014b29a2388",
       "IPY_MODEL_85311277a2c74ed7a0d4c41aa97bfbf4"
      ],
      "layout": "IPY_MODEL_e446da81392a4d2f9418d276c5e630b3"
     }
    },
    "414003e088834d0a8262a655f69834ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92bf696c95e447cc89a052e3b576cb7c",
      "placeholder": "​",
      "style": "IPY_MODEL_ee4e82af6f604d1fb05e003891b1a0d9",
      "value": "Map: 100%"
     }
    },
    "85311277a2c74ed7a0d4c41aa97bfbf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f48b4aeda99649bfa725aa52b33f1deb",
      "placeholder": "​",
      "style": "IPY_MODEL_a2bd55945fe84b8085090022c087fc2d",
      "value": " 5925/5925 [00:01&lt;00:00, 5981.13 examples/s]"
     }
    },
    "92bf696c95e447cc89a052e3b576cb7c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99317d8e00f34a5ba6c6c151c0b5b788": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2bd55945fe84b8085090022c087fc2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e446da81392a4d2f9418d276c5e630b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee4e82af6f604d1fb05e003891b1a0d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f48b4aeda99649bfa725aa52b33f1deb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
