{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMdqB7zUOmPtoIenwgC/oIB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"36e7e451874f4c0e9c30494e34f43e91":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_414003e088834d0a8262a655f69834ba","IPY_MODEL_1d68453c0f784e81be079014b29a2388","IPY_MODEL_85311277a2c74ed7a0d4c41aa97bfbf4"],"layout":"IPY_MODEL_e446da81392a4d2f9418d276c5e630b3"}},"414003e088834d0a8262a655f69834ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92bf696c95e447cc89a052e3b576cb7c","placeholder":"​","style":"IPY_MODEL_ee4e82af6f604d1fb05e003891b1a0d9","value":"Map: 100%"}},"1d68453c0f784e81be079014b29a2388":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_99317d8e00f34a5ba6c6c151c0b5b788","max":5925,"min":0,"orientation":"horizontal","style":"IPY_MODEL_268fe6b11d8e4eb8aeb34ed89458abb1","value":5925}},"85311277a2c74ed7a0d4c41aa97bfbf4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f48b4aeda99649bfa725aa52b33f1deb","placeholder":"​","style":"IPY_MODEL_a2bd55945fe84b8085090022c087fc2d","value":" 5925/5925 [00:01&lt;00:00, 5981.13 examples/s]"}},"e446da81392a4d2f9418d276c5e630b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92bf696c95e447cc89a052e3b576cb7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee4e82af6f604d1fb05e003891b1a0d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99317d8e00f34a5ba6c6c151c0b5b788":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"268fe6b11d8e4eb8aeb34ed89458abb1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f48b4aeda99649bfa725aa52b33f1deb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2bd55945fe84b8085090022c087fc2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3M3357GX0Bob","executionInfo":{"status":"ok","timestamp":1750599937157,"user_tz":-330,"elapsed":12509,"user":{"displayName":"Pranaya Jandial","userId":"08091217684900804801"}},"outputId":"7544e419-1469-456b-edd1-671cf8612efe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n","Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20240930)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n","Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n","Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n","Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n","Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n","Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n","Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n","Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n","Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.13)\n","Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n","Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n","Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n","Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n","Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.6.15)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"]}],"source":["!pip install transformers datasets gradio scikit-learn pandas openai-whisper torch\n","\n","\n"]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","import whisper\n","import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","from datasets import Dataset\n","from transformers import (\n","    BertTokenizerFast,\n","    BertForSequenceClassification,\n","    Trainer,\n","    TrainingArguments,\n","    TextClassificationPipeline\n",")\n","from sklearn.metrics import accuracy_score, f1_score\n","import gradio as gr\n","\n"],"metadata":{"id":"UZo0Tzh71P_f","executionInfo":{"status":"ok","timestamp":1750599960576,"user_tz":-330,"elapsed":23417,"user":{"displayName":"Pranaya Jandial","userId":"08091217684900804801"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# STEP 1: Load and preprocess data\n","df = pd.read_csv('/content/fraud_calls_data.csv', header=None)\n","df.columns = ['label', 'call_text']\n","df = df.dropna(subset=['call_text', 'label'])\n","df['label'] = df['label'].map({'normal': 0, 'fraud': 1})\n","\n"],"metadata":{"id":"_Wzmid7q1P6k","executionInfo":{"status":"ok","timestamp":1750599960579,"user_tz":-330,"elapsed":16,"user":{"displayName":"Pranaya Jandial","userId":"08091217684900804801"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# STEP 2: Tokenization and Hugging Face dataset\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","dataset = Dataset.from_pandas(df[['call_text', 'label']])\n","\n","def tokenize_function(batch):\n","    return tokenizer(batch['call_text'], truncation=True, padding=True, max_length=128)\n","\n","dataset = dataset.map(tokenize_function, batched=True)\n","dataset = dataset.rename_column(\"label\", \"labels\")\n","dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173,"referenced_widgets":["36e7e451874f4c0e9c30494e34f43e91","414003e088834d0a8262a655f69834ba","1d68453c0f784e81be079014b29a2388","85311277a2c74ed7a0d4c41aa97bfbf4","e446da81392a4d2f9418d276c5e630b3","92bf696c95e447cc89a052e3b576cb7c","ee4e82af6f604d1fb05e003891b1a0d9","99317d8e00f34a5ba6c6c151c0b5b788","268fe6b11d8e4eb8aeb34ed89458abb1","f48b4aeda99649bfa725aa52b33f1deb","a2bd55945fe84b8085090022c087fc2d"]},"id":"qQL98VG21P2m","executionInfo":{"status":"ok","timestamp":1750599962874,"user_tz":-330,"elapsed":2294,"user":{"displayName":"Pranaya Jandial","userId":"08091217684900804801"}},"outputId":"b3490626-1765-4c13-b76e-416a14864aa4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5925 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36e7e451874f4c0e9c30494e34f43e91"}},"metadata":{}}]},{"cell_type":"code","source":["\n","# STEP 3: Split dataset\n","data_split = dataset.train_test_split(test_size=0.2)\n","train_dataset = data_split[\"train\"]\n","eval_dataset = data_split[\"test\"]\n","\n"],"metadata":{"id":"qMFt82iV1PzN","executionInfo":{"status":"ok","timestamp":1750599962910,"user_tz":-330,"elapsed":2,"user":{"displayName":"Pranaya Jandial","userId":"08091217684900804801"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["pip install --upgrade transformers\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dk7vK6Wx3CDt","executionInfo":{"status":"ok","timestamp":1750599973862,"user_tz":-330,"elapsed":10950,"user":{"displayName":"Pranaya Jandial","userId":"08091217684900804801"}},"outputId":"6dd3e67b-cae0-4f81-cc87-0e4e994f1781"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"]}]},{"cell_type":"code","source":["# STEP 4: Load and train BERT\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = torch.tensor(logits).argmax(dim=-1)\n","    return {\n","        \"accuracy\": accuracy_score(labels, predictions),\n","        \"f1\": f1_score(labels, predictions)\n","    }\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./bert-fraud-checkpoint\",\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=4,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"accuracy\",\n","    report_to=[]  # Disable wandb\n",")\n","\n","from transformers import DataCollatorWithPadding\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics,\n","    data_collator=data_collator\n",")\n","\n","trainer.train()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":308},"id":"Heox7FD75GnH","executionInfo":{"status":"ok","timestamp":1750600684025,"user_tz":-330,"elapsed":540652,"user":{"displayName":"Pranaya Jandial","userId":"08091217684900804801"}},"outputId":"b0590353-38ae-4f8e-9231-6351b7d03b39"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1188' max='1188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1188/1188 08:58, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.052260</td>\n","      <td>0.988186</td>\n","      <td>0.943089</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.065400</td>\n","      <td>0.053679</td>\n","      <td>0.989873</td>\n","      <td>0.951613</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.065400</td>\n","      <td>0.056989</td>\n","      <td>0.990717</td>\n","      <td>0.955466</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.011700</td>\n","      <td>0.058775</td>\n","      <td>0.990717</td>\n","      <td>0.955466</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1188, training_loss=0.03331900766802958, metrics={'train_runtime': 538.7548, 'train_samples_per_second': 35.192, 'train_steps_per_second': 2.205, 'total_flos': 1247146402406400.0, 'train_loss': 0.03331900766802958, 'epoch': 4.0})"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# STEP 5: Create a text classification pipeline\n","# Load the best model from the checkpoints\n","model_path = trainer.state.best_model_checkpoint\n","if model_path is None:\n","    # If no best model checkpoint is found (e.g., early stopping not used or only one epoch),\n","    # use the last checkpoint or the initial model if only one epoch was run.\n","    # For simplicity, let's assume the model object 'model' is already the trained one\n","    # after trainer.train() completes. If you need to load a specific epoch's model,\n","    # you would typically load from the output_dir.\n","    print(\"No best model checkpoint found, using the model trained in the last epoch.\")\n","    model_to_use = model\n","else:\n","    print(f\"Loading best model from {model_path}\")\n","    model_to_use = BertForSequenceClassification.from_pretrained(model_path)\n","\n","\n","pipeline = TextClassificationPipeline(\n","    model=model_to_use,\n","    tokenizer=tokenizer,\n","    device=0 if torch.cuda.is_available() else -1 # Use GPU if available\n",")\n","\n","# Example usage:\n","example_texts = [\n","    \"Hello, this is a call from your bank regarding a suspicious transaction.\",\n","    \"Hi, just calling to catch up.\",\n","    \"You have won a prize! Please provide your bank details to claim it.\"\n","]\n","\n","print(\"\\nClassifying example texts:\")\n","for text in example_texts:\n","    result = pipeline(text)\n","    predicted_label = \"fraud\" if result[0]['label'] == 'LABEL_1' else \"normal\"\n","    score = result[0]['score']\n","    print(f\"Text: '{text}' -> Predicted: {predicted_label} (Score: {score:.4f})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ry0DdTT4RW7","executionInfo":{"status":"ok","timestamp":1750600684272,"user_tz":-330,"elapsed":250,"user":{"displayName":"Pranaya Jandial","userId":"08091217684900804801"}},"outputId":"1f76009b-1d98-45ec-c5cf-65ab6c85571a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]},{"output_type":"stream","name":"stdout","text":["Loading best model from ./bert-fraud-checkpoint/checkpoint-891\n","\n","Classifying example texts:\n","Text: 'Hello, this is a call from your bank regarding a suspicious transaction.' -> Predicted: fraud (Score: 0.9990)\n","Text: 'Hi, just calling to catch up.' -> Predicted: normal (Score: 0.9998)\n","Text: 'You have won a prize! Please provide your bank details to claim it.' -> Predicted: fraud (Score: 0.9992)\n"]}]},{"cell_type":"code","source":["# STEP 5: Prediction pipeline\n","pipe = TextClassificationPipeline(\n","    model=model,\n","    tokenizer=tokenizer,\n","    return_all_scores=True,\n","    device=0 if torch.cuda.is_available() else -1\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uDqs58f45mr0","executionInfo":{"status":"ok","timestamp":1750600684279,"user_tz":-330,"elapsed":6,"user":{"displayName":"Pranaya Jandial","userId":"08091217684900804801"}},"outputId":"0958a88c-9cdf-4397-eff0-4816e807cace"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n","/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["\n","# STEP 6: Whisper model for transcription\n","whisper_model = whisper.load_model(\"base\")\n","\n","# STEP 7: Risk scoring logic\n","def calculate_risk_score(prob):\n","    if prob >= 0.85:\n","        return \"Critical\"\n","    elif prob >= 0.65:\n","        return \"High\"\n","    elif prob >= 0.35:\n","        return \"Medium\"\n","    else:\n","        return \"Low\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T9qSR_Pv6D6N","executionInfo":{"status":"ok","timestamp":1750600687428,"user_tz":-330,"elapsed":3147,"user":{"displayName":"Pranaya Jandial","userId":"08091217684900804801"}},"outputId":"6565ba01-0afd-4861-b3c9-f4af2ea47e54"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 102MiB/s]\n"]}]},{"cell_type":"code","source":["# STEP 8: Fusion layer for prediction\n","def predict_fraud(text, trust_score):\n","    try:\n","        result = pipe(text)[0]\n","        model_prob = next((item['score'] for item in result if item['label'] == 'LABEL_1'), 0.0)\n","        alpha = 0.7\n","        fused_score = alpha * model_prob + (1 - alpha) * (1 - trust_score)\n","        label = \"Fraud\" if fused_score >= 0.5 else \"Normal\"\n","        risk = calculate_risk_score(fused_score)\n","        return label, f\"{model_prob:.4f}\", f\"{fused_score:.4f}\", risk\n","    except Exception as e:\n","        return \"Error\", \"Error\", \"Error\", str(e)\n","\n"],"metadata":{"id":"yKtmPoE06E5a","executionInfo":{"status":"ok","timestamp":1750600687447,"user_tz":-330,"elapsed":16,"user":{"displayName":"Pranaya Jandial","userId":"08091217684900804801"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# STEP 9: Voice + Trust input wrapper\n","def transcribe_and_predict(audio_file, trust_score):\n","    try:\n","        result = whisper_model.transcribe(audio_file)\n","        transcript = result['text']\n","        prediction = predict_fraud(transcript, trust_score)\n","        return prediction + (transcript,)\n","    except Exception as e:\n","        return \"Error\", \"Error\", \"Error\", str(e), \"\"\n"],"metadata":{"id":"nmGuRql86HOq","executionInfo":{"status":"ok","timestamp":1750600687449,"user_tz":-330,"elapsed":4,"user":{"displayName":"Pranaya Jandial","userId":"08091217684900804801"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# STEP 10: Gradio UI\n","def build_interface():\n","    text_input_tab = gr.Interface(\n","        fn=predict_fraud,\n","        inputs=[\n","            gr.Textbox(label=\"Enter Call Transcript\"),\n","            gr.Slider(minimum=0.0, maximum=1.0, value=0.5, step=0.01, label=\"User Trust Score\")\n","        ],\n","        outputs=[\n","            gr.Label(label=\"Prediction\"),\n","            gr.Label(label=\"Model Fraud Probability\"),\n","            gr.Label(label=\"Fused Risk Score\"),\n","            gr.Label(label=\"Risk Level\")\n","        ],\n","        title=\"Text-based Fraud Detection\",\n","        description=\"Enter a call transcript and trust score to check fraud.\"\n","    )\n","\n","    voice_input_tab = gr.Interface(\n","        fn=transcribe_and_predict,\n","        inputs=[\n","            gr.Audio(type=\"filepath\", label=\"Upload Call Recording (wav/mp3)\"),\n","            gr.Slider(minimum=0.0, maximum=1.0, value=0.5, step=0.01, label=\"User Trust Score\")\n","        ],\n","        outputs=[\n","            gr.Label(label=\"Prediction\"),\n","            gr.Label(label=\"Model Fraud Probability\"),\n","            gr.Label(label=\"Fused Risk Score\"),\n","            gr.Label(label=\"Risk Level\"),\n","            gr.Textbox(label=\"Transcribed Text\")\n","        ],\n","        title=\"Voice-based Fraud Detection\",\n","        description=\"Upload a call recording and get fraud detection with risk analysis.\"\n","    )\n","\n","    demo = gr.TabbedInterface([text_input_tab, voice_input_tab], [\"Text Input\", \"Voice Input\"])\n","    return demo\n"],"metadata":{"id":"DJft1lPh6Lvc","executionInfo":{"status":"ok","timestamp":1750600687460,"user_tz":-330,"elapsed":10,"user":{"displayName":"Pranaya Jandial","userId":"08091217684900804801"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["\n","# Launch the Gradio app\n","build_interface().launch()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":646},"id":"oDvJmWdJ6O-S","executionInfo":{"status":"ok","timestamp":1750600690671,"user_tz":-330,"elapsed":3204,"user":{"displayName":"Pranaya Jandial","userId":"08091217684900804801"}},"outputId":"0d24fa7b-0178-40f4-ea5e-058fb1250f40"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://b872b282e1f6eb7db4.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://b872b282e1f6eb7db4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":18}]}]}